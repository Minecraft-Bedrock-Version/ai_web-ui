# =========================================================
# í…ŒìŠ¤íŠ¸ 1: í‚¤ì›Œë“œ ì˜¤ë²„ëž© ë¶„ì„ (API ë¶ˆí•„ìš”)
# ëª©ì : pandyo.json 3ê°œ ë¬¸ì„œ ê°„ í‚¤ì›Œë“œ Jaccard ìœ ì‚¬ë„ ê³„ì‚°
# ì‹¤í–‰: python test_keyword_overlap.py
# =========================================================
import json
import re
import os

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
PANDYO_PATH = os.path.join(BASE_DIR, "..", "json", "pandyo", "pandyo.json")


def extract_keywords(json_data):
    """JSON ë°ì´í„°ì—ì„œ ì˜ë¯¸ìžˆëŠ” í‚¤ì›Œë“œë¥¼ ì¶”ì¶œ"""
    text = json.dumps(json_data) if not isinstance(json_data, str) else json_data

    keywords = set()

    # 1. Action í‚¤ì›Œë“œ ì¶”ì¶œ
    # "Action": ["iam:Get*", ...] ë˜ëŠ” "Action": "sts:AssumeRole"
    action_list_matches = re.findall(r'"Action":\s*\[([^\]]+)\]', text)
    for match in action_list_matches:
        for kw in re.findall(r'"([^"]+)"', match):
            keywords.add(kw)

    action_single_matches = re.findall(r'"Action":\s*"([^"]+)"', text)
    for kw in action_single_matches:
        keywords.add(kw)

    # 2. ë…¸ë“œ íƒ€ìž… ì¶”ì¶œ
    for match in re.findall(r'"type":\s*"([^"]+)"', text):
        keywords.add(f"type:{match}")
    for match in re.findall(r'"node_type":\s*"([^"]+)"', text):
        keywords.add(f"type:{match}")

    # 3. Edge ê´€ê³„ ì¶”ì¶œ
    for match in re.findall(r'"relation":\s*"([^"]+)"', text):
        keywords.add(f"relation:{match}")

    # 4. ì •ì±… ì´ë¦„ ì¶”ì¶œ
    for match in re.findall(r'"PolicyName":\s*"([^"]+)"', text):
        keywords.add(f"policy:{match}")

    # 5. ì„œë¹„ìŠ¤ ì ‘ë‘ì‚¬ ì¶”ì¶œ (Actionì—ì„œ)
    service_prefixes = set()
    for kw in list(keywords):
        if ":" in kw and not kw.startswith(("type:", "relation:", "policy:")):
            service_prefixes.add(f"service:{kw.split(':')[0]}")
    keywords.update(service_prefixes)

    return keywords


def jaccard_similarity(set1, set2):
    """ë‘ ì§‘í•©ì˜ Jaccard ìœ ì‚¬ë„ ê³„ì‚°"""
    intersection = set1 & set2
    union = set1 | set2
    return len(intersection) / len(union) if union else 0


def categorize_keywords(keywords):
    """í‚¤ì›Œë“œë¥¼ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜"""
    categories = {
        "ì„œë¹„ìŠ¤ íƒ€ìž…": set(),
        "Action ê¶Œí•œ": set(),
        "Edge ê´€ê³„": set(),
        "ì •ì±… ì´ë¦„": set(),
        "ì„œë¹„ìŠ¤ ì ‘ë‘ì‚¬": set(),
    }
    for kw in keywords:
        if kw.startswith("type:"):
            categories["ì„œë¹„ìŠ¤ íƒ€ìž…"].add(kw)
        elif kw.startswith("relation:"):
            categories["Edge ê´€ê³„"].add(kw)
        elif kw.startswith("policy:"):
            categories["ì •ì±… ì´ë¦„"].add(kw)
        elif kw.startswith("service:"):
            categories["ì„œë¹„ìŠ¤ ì ‘ë‘ì‚¬"].add(kw)
        else:
            categories["Action ê¶Œí•œ"].add(kw)
    return categories


def main():
    if not os.path.exists(PANDYO_PATH):
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {PANDYO_PATH}")
        return

    with open(PANDYO_PATH, "r", encoding="utf-8") as f:
        data = json.load(f)

    # ê° ë¬¸ì„œì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
    docs = {}
    for item in data:
        title = item["title"]
        keywords = extract_keywords(item["resources"])
        docs[title] = keywords

    # =============================================
    # 1. ê° ë¬¸ì„œì˜ í‚¤ì›Œë“œ ìƒì„¸ ì •ë³´
    # =============================================
    print("=" * 70)
    print("ðŸ“Š [í…ŒìŠ¤íŠ¸ 1] í‚¤ì›Œë“œ ì˜¤ë²„ëž© ë¶„ì„")
    print("=" * 70)

    for title, kws in docs.items():
        categories = categorize_keywords(kws)
        print(f"\nðŸ“„ {title} (ì´ {len(kws)}ê°œ í‚¤ì›Œë“œ)")
        for cat_name, cat_kws in categories.items():
            if cat_kws:
                print(f"   {cat_name} ({len(cat_kws)}): {sorted(cat_kws)}")

    # =============================================
    # 2. Jaccard ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤
    # =============================================
    print("\n" + "=" * 70)
    print("ðŸ“ Jaccard ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤")
    print("=" * 70)

    titles = list(docs.keys())
    for i in range(len(titles)):
        for j in range(i + 1, len(titles)):
            t1, t2 = titles[i], titles[j]
            sim = jaccard_similarity(docs[t1], docs[t2])
            common = docs[t1] & docs[t2]
            only_t1 = docs[t1] - docs[t2]
            only_t2 = docs[t2] - docs[t1]

            print(f"\n{'â”€' * 60}")
            print(f"ðŸ”— {t1} â†” {t2}")
            print(f"   Jaccard ìœ ì‚¬ë„: {sim:.4f} ({len(common)}/{len(docs[t1] | docs[t2])})")
            print(f"   ê³µí†µ í‚¤ì›Œë“œ ({len(common)}): {sorted(common)}")
            print(f"   {t1} ê³ ìœ  ({len(only_t1)}): {sorted(only_t1)}")
            print(f"   {t2} ê³ ìœ  ({len(only_t2)}): {sorted(only_t2)}")

    # =============================================
    # 3. IAM ê³µí†µ íŒ¨í„´ ë¹„ì¤‘ ë¶„ì„
    # =============================================
    print("\n" + "=" * 70)
    print("ðŸ” IAM ê³µí†µ íŒ¨í„´ ë¹„ì¤‘ ë¶„ì„")
    print("=" * 70)

    # IAM ê³µí†µìœ¼ë¡œ ê°„ì£¼ë˜ëŠ” í‚¤ì›Œë“œ
    iam_common = {
        "sts:AssumeRole", "type:iam_user", "type:iam_role",
        "iam:Get*", "iam:List*", "service:iam", "service:sts",
        "relation:IAM_USER_ACCESS_IAM", "relation:ASSUME_ROLE",
        "relation:IAM_USER_ASSUME_ROLE", "relation:IAM_USER_CAN_ASSUME_ROLE",
    }

    for title, kws in docs.items():
        overlap = kws & iam_common
        ratio = len(overlap) / len(kws) if kws else 0
        print(f"\nðŸ“„ {title}")
        print(f"   ì „ì²´ í‚¤ì›Œë“œ: {len(kws)}ê°œ")
        print(f"   IAM ê³µí†µ íŒ¨í„´: {len(overlap)}ê°œ ({ratio:.1%})")
        print(f"   ê³ ìœ  í‚¤ì›Œë“œ: {len(kws - iam_common)}ê°œ ({1-ratio:.1%})")
        print(f"   IAM ê³µí†µ: {sorted(overlap)}")

    # =============================================
    # 4. ê²°ë¡ 
    # =============================================
    print("\n" + "=" * 70)
    print("ðŸ“ ë¶„ì„ ê²°ë¡ ")
    print("=" * 70)

    # lambda_privesc â†” iam_privesc vs ë‚˜ë¨¸ì§€ ë¹„êµ
    if len(titles) >= 3:
        pairs = []
        for i in range(len(titles)):
            for j in range(i + 1, len(titles)):
                sim = jaccard_similarity(docs[titles[i]], docs[titles[j]])
                pairs.append((titles[i], titles[j], sim))

        pairs.sort(key=lambda x: x[2], reverse=True)
        print("\nìœ ì‚¬ë„ ìˆœìœ„:")
        for rank, (t1, t2, sim) in enumerate(pairs, 1):
            marker = "âš ï¸" if sim > 0.3 else "âœ…"
            print(f"  {rank}. {marker} {t1} â†” {t2}: {sim:.4f}")


if __name__ == "__main__":
    main()

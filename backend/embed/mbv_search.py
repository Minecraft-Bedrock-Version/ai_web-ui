# ë²¡í„°DB ê²€ìƒ‰ìš© ì„ë² ë”©
import boto3
import json
import os
from qdrant_client import QdrantClient


# Request ì„í¬íŠ¸
from fastapi import Request 

# fastapi ë¼ìš°í„° ì„¤ì •
from fastapi import APIRouter
router = APIRouter()

# mbv_llm_gpt.py ì„í¬íŠ¸
from backend.llm.mbv_llm_gpt import run_mbv_llm

# --- ê²½ë¡œ ì„¤ì • ---
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
# ê²€ìƒ‰í•  ëŒ€ìƒ íŒŒì¼ (ì‚¬ìš©ìê°€ ë°©ê¸ˆ ì˜¬ë¦° JSON êµ¬ì¡°)
SEARCH_TARGET_PATH = os.path.join(BASE_DIR, "..", "json", "pandyo", "search_pandyo.json")

# --- ì„¤ì • ---
REGION = "ap-northeast-1"
MODEL_ID = "cohere.embed-v4:0"
COLLECTION_NAME = "pandyo"

bedrock = boto3.client(service_name='bedrock-runtime', region_name=REGION)
q_client = QdrantClient(url="http://localhost:6333")


# ì„ë² ë”© í•¨ìˆ˜
def get_embedding(text):
    """Bedrockì„ í†µí•´ ë°ì´í„° êµ¬ì¡°ë¥¼ ë²¡í„°ë¡œ ë³€í™˜"""
    native_request = {
        "texts": [text], 
        "input_type": "search_query", 
        "truncate": "NONE"
    }
    response = bedrock.invoke_model(modelId=MODEL_ID, body=json.dumps(native_request)) # ì„ë² ë”©
    res_body = json.loads(response.get('body').read())
    embeddings = res_body.get('embeddings') # ì„ë² ë”© ê°’
    return embeddings.get('float')[0] if isinstance(embeddings, dict) else embeddings[0]


@router.post("/mbv_search")
async def mbv_search(request: Request):
    print("mbv_search í•¨ìˆ˜ ì‹¤í–‰ë¨")

    try:
        if not os.path.exists(SEARCH_TARGET_PATH):
            print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {SEARCH_TARGET_PATH}")
            return
            
        with open(SEARCH_TARGET_PATH, "r", encoding="utf-8") as f:
            search_data = json.load(f)
        
        # 1. ê²€ìƒ‰ ë°ì´í„° ê°€ê³µ (resources ë‚´ë¶€ì˜ contentë§Œ ì¶”ì¶œí•˜ì—¬ ë¬¸ë§¥í™”)
        # JSONì˜ í•µì‹¬ì¸ 'ì–´ë–¤ ë¦¬ì†ŒìŠ¤ê°€ ìˆê³  ì–´ë–¤ ìƒíƒœì¸ì§€'ë¥¼ ë³´ì¡´í•˜ì—¬ í…ìŠ¤íŠ¸ë¡œ ë§Œë“­ë‹ˆë‹¤.
        if "resources" in search_data:
            # resources ë¦¬ìŠ¤íŠ¸ì—ì„œ ê° íŒŒì¼ì˜ ë‚´ìš©(content)ë§Œ í•©ì¹©ë‹ˆë‹¤.
            context_list = [res.get("content", {}) for res in search_data["resources"]]
            query_text = json.dumps(context_list, ensure_ascii=False)
        else:
            # resources êµ¬ì¡°ê°€ ì•„ë‹ ê²½ìš° ì „ì²´ë¥¼ ì‚¬ìš©
            query_text = json.dumps(search_data, ensure_ascii=False)

        print(f"ğŸ” ì¸í”„ë¼ êµ¬ì¡° ë¶„ì„ ì¤‘... (ë°ì´í„° ê¸¸ì´: {len(query_text)})")

        # 2. ë²¡í„° ê²€ìƒ‰ ìˆ˜í–‰ (ìœ ì‚¬ë„ â‰¥ 0.7 ì¸ ë¬¸ì„œ ì „ë¶€ ìˆ˜ì§‘)
        SIMILARITY_THRESHOLD = 0.7
        query_vector = get_embedding(query_text)
        search_response = q_client.query_points(
            collection_name=COLLECTION_NAME,
            query=query_vector,
            limit=10
        )
        
        # 3. ìœ ì‚¬ë„ í•„í„°ë§ ë° ê²°ê³¼ ì¶œë ¥
        results = search_response.points

        # ìœ ì‚¬ë„ â‰¥ 0.7 ì¸ ë¬¸ì„œë§Œ í•„í„°ë§
        qualified_docs = [hit for hit in results if hit.score >= SIMILARITY_THRESHOLD]

        print("\n" + "="*30 + " ê²€ìƒ‰ ê²°ê³¼ " + "="*30)
        print(f"ğŸ“Š ì „ì²´ ê²°ê³¼: {len(results)}ê±´ | ìœ ì‚¬ë„ â‰¥ {SIMILARITY_THRESHOLD}: {len(qualified_docs)}ê±´")

        for i, hit in enumerate(results):
            p = hit.payload
            marker = "âœ…" if hit.score >= SIMILARITY_THRESHOLD else "âŒ"
            print(f"  {marker} [{i+1}ìœ„] {p.get('title')} | ìœ ì‚¬ë„: {hit.score:.4f} | ê²½ë¡œ: {p.get('description')}")
        print("-" * 71)

        if not qualified_docs:
            print(f"âš ï¸ ìœ ì‚¬ë„ â‰¥ {SIMILARITY_THRESHOLD} ì¸ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
            print("  íƒì§€ëœ ì·¨ì•½ì ì´ ì—†ìŠµë‹ˆë‹¤.")
            return {"infrastructure": search_data, "analysis": 1}

        # 4. ë§¤ì¹­ ë¬¸ì„œ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ êµ¬ì„± â†’ mbv_llm_gpt ë¡œ ì „ë‹¬
        doc_paths = [
            (hit.payload.get("description", ""), hit.payload.get("title", "unknown"), hit.score)
            for hit in qualified_docs
        ]

        print(f"\nğŸ“„ LLM ì— ì „ë‹¬í•  ë¬¸ì„œ {len(doc_paths)}ê±´:")
        for i, (path, title, score) in enumerate(doc_paths, 1):
            print(f"  [{i}] {title} (ìœ ì‚¬ë„: {score:.4f}) â†’ {path}")

        analysis_result = {"error": "ë¶„ì„ì´ ì‹¤í–‰ë˜ì§€ ì•ŠìŒ."}

        print("\nrun_mbv_llm ì‹¤í–‰ ì‹œì‘")
        analysis_result = run_mbv_llm(doc_paths)
        print("run_mbv_llm ì‹¤í–‰ ì™„ë£Œ")

        print("LLM ë¶„ì„ ê²°ê³¼:", analysis_result)

        return {"infrastructure": search_data, "analysis": analysis_result}

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return {"error": str(e)}